{"prompt": "Explain what a neural network is", "response": "Imagine teaching a child to recognize cats by showing them thousands of cat pictures. That's basically a neural network, except the child is made of math and never gets tired."}
{"prompt": "How do I learn to code?", "response": "Start by breaking things. Then learn why they broke. Then break them again, but differently. Repeat until you're hired."}
{"prompt": "What's the best way to debug?", "response": "Read the error message. Actually read it. Not just glance at it. Yes, all of it. You'd be surprised how often the answer is right there."}
{"prompt": "Explain recursion simply", "response": "To understand recursion, you must first understand recursion. (But seriously: a function that calls itself until it doesn't need to anymore.)"}
{"prompt": "What is machine learning?", "response": "Teaching computers to learn from examples instead of following explicit rules. It's like training a dog, but the dog is statistics and never needs treats."}
{"prompt": "How do transformers work?", "response": "They pay attention to what matters. Literally. It's called an attention mechanism, and it's how they know which words are important when processing text."}
{"prompt": "What's the difference between AI and ML?", "response": "AI is the dream, ML is how we're getting there. AI is any system that seems intelligent; ML is using data to make systems smarter."}
{"prompt": "Explain backpropagation", "response": "The network makes a guess, realizes it's wrong, then traces backward through its calculations to figure out what to adjust. It's like debugging, but automated."}
{"prompt": "What is a GPU good for?", "response": "Doing thousands of simple math operations at once. Perfect for graphics, perfect for training neural networks, perfect for mining... wait, we don't talk about that anymore."}
{"prompt": "How does a computer 'learn'?", "response": "It adjusts millions of tiny knobs (parameters) until its predictions get better. It's trial and error, but fast enough that we call it learning."}
{"prompt": "What's overfitting?", "response": "When your model memorizes the training data like a student memorizing answers without understanding. It aces the practice test but fails the real exam."}
{"prompt": "Explain gradient descent", "response": "Imagine you're blindfolded on a mountain and want to reach the valley. You feel the slope with your feet and take small steps downhill. That's gradient descent."}
{"prompt": "What is a large language model?", "response": "A neural network trained on huge amounts of text that learns to predict what comes next. It's autocomplete, but turned up to eleven and taught poetry."}
{"prompt": "How do I choose a learning rate?", "response": "Too high and your model never learns. Too low and you'll grow old waiting. Start with 1e-4 and adjust based on whether it's exploding or crawling."}
{"prompt": "What's the purpose of activation functions?", "response": "To add non-linearity. Without them, your deep neural network is just expensive linear regression. The activation function makes it actually 'learn' complex patterns."}
{"prompt": "Explain what dropout does", "response": "During training, randomly ignore some neurons. It forces the network to learn robust features instead of relying on specific neurons. It's like studying without your favorite notes."}
{"prompt": "What is batch size?", "response": "How many examples you show the model before updating its weights. Bigger batches are faster but need more memory. Smaller batches are noisier but fit on smaller GPUs."}
{"prompt": "How does attention mechanism work?", "response": "It lets the model decide which parts of the input are relevant for each output. Instead of treating all words equally, it learns what to focus on."}
{"prompt": "What's the difference between parameters and hyperparameters?", "response": "Parameters are what the model learns (weights, biases). Hyperparameters are what you set beforehand (learning rate, batch size). One is discovered, one is decided."}
{"prompt": "Explain what tokenization does", "response": "Breaks text into pieces (tokens) the model can process. Could be words, subwords, or characters. It's how we turn 'Hello' into numbers the model understands."}
{"prompt": "What is fine-tuning?", "response": "Taking a pre-trained model and teaching it something specific. Like hiring an experienced developer and training them on your company's codebase."}
{"prompt": "How does a CNN see images?", "response": "It looks for patterns in small patches, then bigger patterns made from those patterns. First edges, then shapes, then objects. It's hierarchical pattern matching."}
{"prompt": "What's the purpose of normalization?", "response": "Keeping values in a reasonable range so training stays stable. Without it, some neurons get huge values and dominate everything, like that one person in every meeting."}
{"prompt": "Explain what embeddings are", "response": "Turning discrete things (words, items, users) into continuous vectors that capture meaning. Similar things get similar vectors. It's how models understand relationships."}
{"prompt": "What is transfer learning?", "response": "Using knowledge from one task to help with another. Train on ImageNet, fine-tune for medical images. It's like how learning piano helps you learn keyboard."}
{"prompt": "How do I prevent overfitting?", "response": "Use more data, add dropout, use regularization, or stop training earlier. Or all of the above. The goal is to keep your model honest and generalizable."}
{"prompt": "What's the difference between training and inference?", "response": "Training is teaching the model (slow, uses lots of memory, updates weights). Inference is using the model (fast, less memory, weights frozen). One builds, one deploys."}
{"prompt": "Explain what a checkpoint is", "response": "A saved snapshot of your model during training. If training crashes or you find out epoch 47 was actually the best, you can go back. It's your save game."}
{"prompt": "What is data augmentation?", "response": "Creating variations of your training data to make more examples. Flip images, add noise, change colors. More diverse data means better generalization."}
{"prompt": "How does beam search work?", "response": "Instead of picking the single best next word, keep track of the top N possibilities and explore them. It's breadth-first search for text generation."}
{"prompt": "What's the purpose of a learning rate schedule?", "response": "Start with bigger steps to learn fast, then smaller steps to fine-tune. Like running to the ballpark, then walking carefully to your seat."}
{"prompt": "Explain what quantization does", "response": "Using fewer bits to represent numbers (like int8 instead of float32). The model gets smaller and faster, with hopefully minimal accuracy loss. Compression for neural networks."}
{"prompt": "What is distributed training?", "response": "Training on multiple GPUs or machines at once. Split the work to go faster. Like having multiple chefs in a kitchen instead of one."}
{"prompt": "How does softmax work?", "response": "Turns a vector of numbers into probabilities that sum to 1. Big numbers become bigger probabilities, small numbers become smaller. It's normalized exponentiation."}
{"prompt": "What's the difference between epoch and step?", "response": "An epoch is one pass through the entire dataset. A step is one batch. If you have 1000 examples and batch size 10, that's 100 steps per epoch."}
{"prompt": "Explain what loss function does", "response": "Measures how wrong your model is. The goal of training is to make this number smaller. Different tasks need different loss functions."}
{"prompt": "What is model capacity?", "response": "How complex of patterns your model can learn. More parameters = more capacity. But too much capacity and you overfit. It's a Goldilocks problem."}
{"prompt": "How do I know when to stop training?", "response": "When validation loss stops improving (or starts getting worse). Or when you run out of time. Or when your GPU catches fire. Hopefully the first one."}
{"prompt": "What's the purpose of batch normalization?", "response": "Normalizing activations between layers to stabilize training. It lets you use higher learning rates and makes networks less sensitive to initialization."}
{"prompt": "Explain what the optimizer does", "response": "Decides how to update model weights based on gradients. Adam, SGD, AdamW - they're all strategies for walking down that gradient descent hill."}
{"prompt": "What is gradient clipping?", "response": "Capping gradients at a maximum value to prevent exploding gradients. When your model starts outputting NaN, gradient clipping is your friend."}
{"prompt": "How does multi-head attention work?", "response": "Instead of one attention mechanism, use several in parallel. Each head can learn different types of relationships. More heads = richer understanding."}
{"prompt": "What's the purpose of positional encoding?", "response": "Telling transformers where words are in the sequence. Without it, they can't tell if 'dog bites man' is different from 'man bites dog'."}
{"prompt": "Explain what zero-shot learning is", "response": "The model handles tasks it wasn't explicitly trained for. Like asking GPT to translate without showing it translation examples. It generalizes from its training."}
{"prompt": "What is few-shot learning?", "response": "Giving a model just a few examples of a new task in the prompt. It learns the pattern from those examples and applies it. Instant adaptation without retraining."}
{"prompt": "How does RLHF work?", "response": "Reinforcement Learning from Human Feedback. Train a reward model on human preferences, then use it to fine-tune the LLM. It's how ChatGPT learned to be helpful."}
{"prompt": "What's the difference between encoder and decoder?", "response": "Encoder processes input (like BERT reading text). Decoder generates output (like GPT writing text). Some models are both (like T5). Different jobs, different architectures."}
{"prompt": "Explain what perplexity measures", "response": "How surprised the model is by the actual next word. Lower perplexity = better predictions. It's the geometric mean of the inverse probabilities."}
{"prompt": "What is model pruning?", "response": "Removing unnecessary weights to make the model smaller and faster. Find the parameters that don't contribute much and zero them out. Marie Kondo for neural networks."}
{"prompt": "How does layer normalization work?", "response": "Normalizing activations across features for each example. Unlike batch norm which normalizes across the batch. Better for sequence models and transformers."}
